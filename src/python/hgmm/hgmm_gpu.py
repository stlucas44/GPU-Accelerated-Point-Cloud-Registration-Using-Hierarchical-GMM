# -*- coding: utf-8 -*-
"""hgmm_cupy_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dRqykhVzDFJBgGjLjqWxl8I0LkAD0Twn
"""

from __future__ import print_function
from __future__ import division
import matplotlib.pyplot as plt
from sklearn import cluster, datasets, mixture
import numpy as np
from scipy.stats import multivariate_normal
from sklearn.datasets import make_spd_matrix
plt.rcParams["axes.grid"] = False
import os
#os.environ['NUMBAPRO_LIBDEVICE'] = "/usr/local/cuda-10.0/nvvm/libdevice"
#os.environ['NUMBAPRO_NVVM'] = "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so"
from numba import cuda
from numba.types import float32
import math
import cupy as cp
from collections import namedtuple
import open3d as o3
import transformations as trans

eps = np.float32(1.0e-15)
n_node = 8

# class node:
#     def __init__(self):
#         self.mixingCoeff = 0.0
#         self.mean = np.zeros(3,dtype=np.float32)
#         self.covar = np.identity(3,dtype= np.float32)

#     def set_mixingCoeff(self,mixingCoeff):
#         self.mixingCoeff = mixingCoeff

#     def set_mean(self,mean):
#         self.mean = mean

#     def set_covar(self,covar):
#         self.covar = covar

# class moment:
#     def __init__(self):
#         self.zero = 0.0
#         self.one = np.zeros(3,dtype= np.float32)
#         self.two = np.zeros((3,3),dtype= np.float32)

#     def set_zero(self,zero):
#         self.zero = zero

#     def set_one(self,one):
#         self.one = one

#     def set_two(self,two):
#         self.two = two

# def logLikelihoodValue(nodes,data,j0,j1):
#     q = 0.0
#     #print("j0 is: ",j0)
#     #print("j1 is: ",j1)
#     #print("Points are of: ",data.shape[0])
#     for i in range (data.shape[0]):
#         temp = 0.0
#         for j in range(int(j0),int(j1)):
#             if (nodes[j].mixingCoeff < eps):
#                 continue
#             temp = temp + nodes[j].mixingCoeff * gaussianPdf(data[i],nodes[j].mean,nodes[j].covar)
#         q = q + np.log(max(temp,eps))

#     return q


def complexity(cov):
  #pdb.set_trace()
    lamds,vec = np.linalg.eig(cov)
    lamds[::-1].sort()
    return lamds[2]/np.sum(lamds)

@cuda.jit(device=True)
def child(j):
    return (j+1) * n_node

def child2(j):
    return (j+1) * n_node

def level(l):
    return n_node * (np.power(n_node,l) -1 )/ (n_node -1)

def gaussianPdf(data,mu,cov):
    d = data - mu
    #print(type(cov))
    det = np.linalg.det(cov)
    if(det < eps):
        return 0.0
    c = 1.0/(np.power(det,0.5) * np.power(2.0 * np.pi, len(data) *0.5))
    ep = -0.5 * np.matmul(d,np.matmul(np.linalg.inv(cov),d.T))
    return c * np.exp(ep)

D = 3
SQRT_TWOPI = np.float32(math.sqrt((2*math.pi)**D))

@cuda.jit
def logLikelihoodValue(mixingCoeff,mean,covar,data,j0,j1,q):
    idx = (cuda.blockDim.x * cuda.blockIdx.x) + cuda.threadIdx.x
    if (idx >= data.shape[0]):
        return
    temp = 0.0
    for j in range(j0,j1):
        temp = temp + (mixingCoeff[j] * gaussianPdfKernel(data[idx],mean[j],covar[j]))
    q[idx] = math.log(max(temp,eps))


@cuda.jit(device=True)
def invert(m, mout):
    if m.shape == (3,3):
        m1, m2, m3, m4, m5, m6, m7, m8, m9 = m[0,0],m[0,1],m[0,2],\
                                            m[1,0],m[1,1],m[1,2],\
                                            m[2,0],m[2,1],m[2,2]

        det = m1*m5*m9 + m4*m8*m3 + m7*m2*m6 - m1*m6*m8 - m3*m5*m7 - m2*m4*m9

        mout[0,0] = (m5*m9-m6*m8)/det
        mout[0,1] = (m3*m8-m2*m9)/det
        mout[0,2] = (m2*m6-m3*m5)/det
        mout[1,0] = (m6*m7-m4*m9)/det
        mout[1,1] = (m1*m9-m3*m7)/det
        mout[1,2] = (m3*m4-m1*m6)/det
        mout[2,0] = (m4*m8-m5*m7)/det
        mout[2,1] = (m2*m7-m1*m8)/det
        mout[2,2] = (m1*m5-m2*m4)/det
    elif m.shape==(2,2):
        a, b, c, d = m[0][0], m[0][1], m[1][0], m[1][1]
        det = a*d - b*c
        mout[0,0] = d/det
        mout[0,1] = -b/det
        mout[1,0] = -c/det
        mout[1,1] = a/det
    else:
        raise TypeError("Not supported")

@cuda.jit(device=True)
def matmul(a, b, c):
    m, n = a.shape
    _, p = b.shape

    for i in range(m):
        for j in range(p):
            c[i][j] = 0.0
            for k in range(n):
                c[i][j] += a[i][k] * b[k][j]

@cuda.jit(device=True)
def sub(a, b, out):
    n = a.shape[0]
    for i in range(n):
        out[i,0] = a[i] - b[i]

@cuda.jit(device=True)
def addZerosVec(a):
    n = a.shape[0]
    for i in range(n):
        a[i,0] = 0.0

@cuda.jit(device=True)
def addZerosMat(a):
    m,n = a.shape
    for i in range(m):
        for j in range(n):
            a[i,j] = 0.0

@cuda.jit(device=True)
def vecSum(a, b, out):
    n = a.shape[0]
    for i in range(n):
        out[i,0] = a[i] + b[i]

@cuda.jit(device=True)
def copyVecToMat(a, out):
    n = a.shape[0]
    for i in range(n):
        out[0,i] = a[i]

@cuda.jit(device=True)
def matmultConstant(const,a,out):
    m,n = a.shape
    for i in range(m):
        for j in range(n):
            out[i,j] = const*a[i,j]

@cuda.jit(device = True)
def matAdd(a,b,out):
    m,n = a.shape
    for i in range(m):
        for j in range(n):
            out[i,j] = a[i,j] + b[i,j]

@cuda.jit(device=True)
def copy(a, a_out):
    n = a.shape[0]
    for i in range(n):
        a_out[i] = a[i]

@cuda.jit(device=True)
def transpose_mat(m, mout):
    nr, nc = m.shape
    for i in range(nr):
        for j in range(nc):
            mout[j,i] = m[i,j]

@cuda.jit(device=True)
def copyVec3x1(m,mout):
    n = m.shape[0]
    for i in range(n):
        mout[i,0] = m[i]

@cuda.jit(device=True)
def transpose_vec(m, mout):
    n = m.shape[0]
    for i in range(n):
            mout[i,0] = m[i]

@cuda.jit(device = True)
def vecMult(gamma,m,mout):
    n = m.shape[0]
    for i in range(n):
        mout[i,0] = m[i] * gamma

@cuda.jit(device=True)
def determinant(a):
    if(a.shape == (3,3)):
        det = a[0][0]*((a[1][1]*a[2][2]) - (a[2][1]*a[1][2])) -\
        a[0][1] * (a[1][0]* a[2][2] - a[2][0] * a[1][2]) +\
        a[0][2] * (a[1][0] * a[2][1] - a[2][0] * a[1][1])

        return det
    elif(a.shape == (2,2)):
        det = a[0][0]*a[1][1] - a[0][1]*a[1][0]
        return det
    else:
        raise TypeError("Not supported")

@cuda.jit(device = True)
def mlEstimator(momentZero,momentOne,momentTwo,mixingCoeff,mean,covar,idx,nTotal,ld):

#   if (momentZero < ld):
#       mixingCoeff[idx] = 0.0
#       for i in range(len(mean)):
#           mean[idx,i] = 0.0
#       addZerosMat(covar[idx])

#   else:
    mixingCoeff[idx] = momentZero/nTotal

    for i in range(len(mean[idx])):
        mean[idx,i] = momentOne[i]/momentZero

    meanNew = cuda.local.array((D,1), float32)
    copyVec3x1(mean[idx],meanNew)
    mean_tran = cuda.local.array((1,D), float32)
    transpose_mat(meanNew,mean_tran)

    out_temp = cuda.local.array((D,D),float32)
    for i in range(D):
        for j in range(D):
            out_temp[i,j] = momentTwo[i,j]/momentZero

    out2 = cuda.local.array((D,D),float32)
    matmul(meanNew,mean_tran,out2)

    for i in range(D):
        for j in range(D):
            covar[idx,i,j] =out_temp[i,j] - out2[i,j]
  #print("The mixing coefficient is before return is:",n1.mixingCoeff)


#os.environ['NUMBA_ENABLE_CUDASIM'] = '1'
from pdb import set_trace

@cuda.jit(device=True)
def gaussianPdfKernel(x, mu, cov):
    x_mu = cuda.local.array((D,1), float32)
    sub(x, mu, x_mu)
    det = determinant(cov)

    if(det < eps):
        return 0.0

    cov_inv = cuda.local.array((D,D), float32)
    invert(cov, cov_inv)


    factor = 1.0/(SQRT_TWOPI * math.sqrt(det))

    cov_x_mu = cuda.local.array((D,1), float32)
    matmul(cov_inv, x_mu, cov_x_mu)

    x_mu_t = cuda.local.array((1,D), float32)
    transpose_mat(x_mu, x_mu_t)

    prob = cuda.local.array((1,1), float32)
    matmul(x_mu_t, cov_x_mu, prob)

    p = -0.5 * prob[0,0]
    p = math.exp(p)

    out = factor * p
    return out

@cuda.jit(device=True)
def normalizeKernel(gamma,n_node,sumGamma):
    maxj = 0
    for j in range(n_node):
        gamma[j] = gamma[j] * np.float32(1.0/sumGamma)
        if (gamma[j] > gamma[maxj]):
            maxj = j

    return maxj

@cuda.jit(device = True)
def accumulateDevice(momentZero,momentOne,momentTwo,j,gamma,point,sumGamma):

    gamma2 = gamma[0]/np.float32(sumGamma)
    if (gamma2 < eps):
        return
    #print(gamma2)
    cuda.atomic.add(momentZero,j,gamma2)

    #out = cuda.local.array((D,1),float32)
    #out2 = cuda.local.array((D,1),float32)
    #vecMult(gamma2,point,out)
    #vecSum(momentOne[j],out[:,0],out2)

    #for i in range(D):
    cuda.atomic.add(momentOne ,(j,0), gamma2 * point[0])
    cuda.atomic.add(momentOne ,(j,1), gamma2 * point[1])
    cuda.atomic.add(momentOne ,(j,2), gamma2 * point[2])

    pointNew = cuda.local.array((D,1),dtype = float32)
    copyVec3x1(point,pointNew)
    point_trans = cuda.local.array((1,D),dtype = float32)
    transpose_mat(pointNew,point_trans)
    out3 = cuda.local.array((D,D),dtype = float32)
    matmul(pointNew,point_trans,out3)

    cuda.atomic.add(momentTwo ,(j,0,0), gamma2 * out3[0,0])
    cuda.atomic.add(momentTwo ,(j,0,1), gamma2 * out3[0,1])
    cuda.atomic.add(momentTwo ,(j,0,2), gamma2 * out3[0,2])
    cuda.atomic.add(momentTwo ,(j,1,0), gamma2 * out3[1,0])
    cuda.atomic.add(momentTwo ,(j,1,1), gamma2 * out3[1,1])
    cuda.atomic.add(momentTwo ,(j,1,2), gamma2 * out3[1,2])
    cuda.atomic.add(momentTwo ,(j,2,0), gamma2 * out3[2,0])
    cuda.atomic.add(momentTwo ,(j,2,1), gamma2 * out3[2,1])
    cuda.atomic.add(momentTwo ,(j,2,2), gamma2 * out3[2,2])

    #for i in range(D):
    #    momentOne[i] = out2[i,0]

    # point_trans = cuda.local.array((D,1),float32)
    # transpose_vec(point,point_trans)
    # #point = point.reshape(1,-1)
    # out3 = cuda.local.array((D,D),dtype = float32)
    # vecCheck = cuda.local.array((1,D),float32)
    # copyVecToMat(point,vecCheck)
    # matmul(point_trans,vecCheck,out3)
    # out4 = cuda.local.array((D,D),dtype = float32)
    # #elementMult(gamma,)
    # matmultConstant(gamma2,out3,out4)
    # out5 = cuda.local.array((D,D),dtype = float32)
    # matAdd(momentTwo[j],out4,out5)

    # for i in range(D):
    #     for j in range(D):
    #         momentTwo[i,j] = out5[i,j]


@cuda.reduce
def sum_reduce(a, b):
    return a + b

TPB = 100

@cuda.jit
def gmmTreeEStepKernel(data,mixingCoeff,mean,covar,momentsZero,momentsOne,momentsTwo,parentIdx,currentIdx,nTotal):

    idx = (cuda.blockDim.x * cuda.blockIdx.x) + cuda.threadIdx.x
    if (idx >= data.shape[0]):
        return
    j0 = child(parentIdx[idx])
    gamma = cuda.local.array((n_node,1),float32)
    sumGamma = np.float32(0.0)
    maxj = 0
    for j in range(j0,j0+n_node):
        p = mixingCoeff[j] * gaussianPdfKernel(data[idx],mean[j],covar[j])
        gamma[j-j0] = p
        if (np.float32(p) > gamma[maxj,0]):
            maxj = j-j0
        sumGamma = sumGamma + p

    if (sumGamma < eps):
        for j in range(n_node):
            gamma[j] = 0.0

    for j in range(j0,j0+n_node):
        k = gamma[j- j0]
        accumulateDevice(momentsZero,momentsOne,momentsTwo,j,k,data[idx],sumGamma)
    currentIdx[idx] = j0 + maxj

    #if idx < 10:
    #    print(maxj)
    #if idx==1:
    #    for i in range(7):
    #        print(momentsZero[i])



@cuda.jit
def gmmtreeMStepKernel(momentsZero,momentsOne,momentsTwo,mixingCoeff,mean,covar,n_points,lb,le,ld):
    idx = (cuda.blockDim.x * cuda.blockIdx.x) + cuda.threadIdx.x
    if (idx >= le - lb):
        return
    mlEstimator(momentsZero[idx+lb],momentsOne[idx + lb],momentsTwo[idx + lb],mixingCoeff,mean,covar,idx+lb,n_points,ld)

# @cuda.jit
# def gmmTreeRegEStep(points,nodes,moments,maxTreeLevel,nTotal,lc):
#     idx = (cuda.blockDim.x * cuda.blockIdx.x) + cuda.threadIdx.x
#     searchID = -1
#     gamma = cuda.local.array((n_node,1),float32)
#     for l in range(maxTreeLevel):
#         j0 = int(child(searchID))
#         for j in range(j0,j0+n_node):
#             gamma[j-j0] = nodes[j].mixingCoeff * gaussianPdf(data[idx],nodes[j].mean,nodes[j].covar)
#         sumGamma = sumFunc(gamma,n_node)

#         maxj = 0
#         if (sumGamma < eps):
#             for j in range(n_node):
#                 gamma[i] = 0

#         else:
#             for j in range(n_node)
#                 gamma[i] = gamma[i]/sumGamma
#                 if (gamma[i] > gamma[maxj]):
#                     maxj = i
#         searchID = maxj
#         searchID = searchID + j0
#         if(complexity(nodes[searchID].covar <= lc)):
#             break
#         accumulate(moments[searchID],gamma[searchID - j0],points[idx])

blockSize = 128

def accumulate(momentZero,momentOne,momentTwo,searchID,gamma,data):
  if (float(gamma) <  eps):
    return

  momentZero[searchID] = momentZero[searchID] + gamma
  data = data.reshape(1,-1)
  momentOne[searchID] = momentOne[searchID] + float(gamma)*data
  momentTwo[searchID] = momentTwo[searchID] + float(gamma)*np.matmul(data.T,data)

def buildGMMTree(points,maxTreeLevel,ls,ld):
    nTotal = int(n_node * (np.power(n_node,maxTreeLevel) -1 )/(n_node-1))
    print("total components:", nTotal)
    np.random.seed(72)
    idxs = np.random.randint(nTotal,size = nTotal)
    points = points.astype(np.float32)
    #sig2 = cp.var(points)
    #print("Variance is:",sig2/(3*n_node))
    #for i in range(5):
    #    print(points[i])
    #sig2 = 0.00034
    sig2 = 0.004

    mixingCoeff = np.zeros(nTotal,dtype = np.float32)
    mean = np.zeros((nTotal,3),dtype = np.float32)
    covar = np.zeros((nTotal,3,3),dtype = np.float32)

    momentsZero = np.zeros(nTotal,dtype = np.float32)
    momentsOne = np.zeros((nTotal,3),dtype = np.float32)
    momentsTwo = np.zeros((nTotal,3,3),dtype = np.float32)

    for i in range(nTotal):
        mixingCoeff[i] = (1.0/n_node)
        mean[i] = points[idxs[i]]
        covar[i] = np.identity(3,dtype = np.float32) * sig2

    print(type(mixingCoeff[0]))
    parentIdx = -1*np.ones(points.shape[0],dtype = int)
    currentIdx = np.zeros(points.shape[0],dtype = int)
    dev_parentIdx = cuda.to_device(parentIdx)
    dev_currentIdx = cuda.to_device(currentIdx)

    dev_mixingCoeff = cuda.to_device(mixingCoeff)
    dev_mean = cuda.to_device(mean)
    dev_covar = cuda.to_device(covar)

    dev_momentsZero = cuda.to_device(momentsZero)
    dev_momentsOne = cuda.to_device(momentsOne)
    dev_momentsTwo = cuda.to_device(momentsTwo)

    dev_momentsZero_N = cuda.to_device(momentsZero.copy())
    dev_momentsOne_N = cuda.to_device(momentsOne.copy())
    dev_momentsTwo_N = cuda.to_device(momentsTwo.copy())

    dev_points = cuda.to_device(points)

    qValues = cuda.device_array(points.shape[0],dtype = np.float32)
    fullNumBlocks1 = int((points.shape[0] + blockSize - 1)/blockSize)
    dev_maxTreeLevel = cuda.to_device(maxTreeLevel)
    dev_nTotal = cuda.to_device(nTotal)

    print("start")
    t1 = time.time()
    for l in range(maxTreeLevel):
        prevQ = 0.0
        while (True):
            gmmTreeEStepKernel[fullNumBlocks1,blockSize](dev_points,dev_mixingCoeff,dev_mean,dev_covar,dev_momentsZero,dev_momentsOne,dev_momentsTwo,dev_parentIdx,dev_currentIdx,dev_nTotal)
            #cuda.synchronize()
            lb = level(l)
            le = level(l+1)

            fullNumBlocks2 = int((le -lb + blockSize - 1)/blockSize)
            gmmtreeMStepKernel[fullNumBlocks2,blockSize](dev_momentsZero,dev_momentsOne,dev_momentsTwo,dev_mixingCoeff,dev_mean,dev_covar,np.float32(points.shape[0]),int(lb),int(le),np.float32(ld))
            #cuda.synchronize()
            logLikelihoodValue[fullNumBlocks1,blockSize](dev_mixingCoeff,dev_mean,dev_covar,dev_points,int(level(l)),int(level(l+1)),qValues)
            #cuda.synchronize()
            q = sum_reduce(qValues)
            if (np.abs(q - prevQ) < ls):
                break
            prevQ = q
            dev_momentsZero.copy_to_device(dev_momentsZero_N)
            dev_momentsOne.copy_to_device(dev_momentsOne_N)
            dev_momentsTwo.copy_to_device(dev_momentsTwo_N)

        dev_parentIdx.copy_to_device(dev_currentIdx)
    t2 = time.time()

    print('Time: ', t2-t1)
    #print("Nodes is",nodes)
    mixingCoeff = dev_mixingCoeff.copy_to_host()
    mean = dev_mean.copy_to_host()
    covar = dev_covar.copy_to_host()
    return mixingCoeff,mean,covar

def gmmTreeRegESTep(points,mixingCoeff,mean,covar,maxTreeLevel,lc):
  #print("Node value is: ",nodes[0].mixingCoeff,nodes[0].mean,nodes[0].covar)
  nTotal = int(n_node * (np.power(n_node,maxTreeLevel) -1 )/(n_node-1))
  momentsZero = np.zeros(nTotal,dtype = np.float32)
  momentsOne = np.zeros((nTotal,3),dtype = np.float32)
  momentsTwo = np.zeros((nTotal,3,3),dtype = np.float32)

  for i in range(points.shape[0]):
    searchID = -1
    gamma = np.zeros(n_node)
    for l in range(maxTreeLevel):
      j0 = int(child2(searchID))
      for j in range(j0,j0+n_node):
        gamma[j - j0] = mixingCoeff[j] * gaussianPdf(points[i],mean[j],covar[j])
      den = np.sum(gamma)
      if (float(den) > eps):
        gamma = gamma/den
      else:
        gamma = np.zeros(n_node)

      searchID = np.argmax(gamma)
      searchID = searchID + j0
      if (complexity(covar[searchID]) <= lc):
        break
      k = gamma[searchID- j0]
      accumulate(momentsZero,momentsOne,momentsTwo,searchID,k,points[i])

  return momentsZero,momentsOne,momentsTwo

import abc
import six
import time

@six.add_metaclass(abc.ABCMeta)
class Transformation():
    def __init__(self):
        pass

    def transform(self, points,
                  array_type=o3.utility.Vector3dVector):
        if isinstance(points, array_type):
            return array_type(self._transform(np.asarray(points)))
        return self._transform(points)

    @abc.abstractmethod
    def _transform(self, points):
        return points


class RigidTransformation(Transformation):
    """Rigid Transformation
    Args:
        rot (numpy.ndarray, optional): Rotation matrix.
        t (numpy.ndarray, optional): Translation vector.
        scale (Float, optional): Scale factor.
    """
    def __init__(self, rot=np.identity(3),
                 t=np.zeros(3), scale=1.0):
        super(RigidTransformation, self).__init__()
        self.rot = rot
        self.t = t
        self.scale = scale

    def _transform(self, points):
        return self.scale * np.dot(points, self.rot.T) + self.t

    def inverse(self):
        return RigidTransformation(self.rot.T, -np.dot(self.rot.T, self.t),
                                   1.0 / self.scale)

def skew(x):
    """
    skew-symmetric matrix, that represent
    cross products as matrix multiplications.
    Args:
        x (numpy.ndarray): 3D vector.
    Returns:
        3x3 skew-symmetric matrix.
    """
    return np.array([[0.0, -x[2], x[1]],
                     [x[2], 0.0, -x[0]],
                     [-x[1], x[0], 0.0]])


def twist_mul(tw, rot, t, linear=False):
    """
    Multiply twist vector and transformation matrix.
    Args:
        tw (numpy.ndarray): Twist vector.
        rot (numpy.ndarray): Rotation matrix.
        t (numpy.ndarray): Translation vector.
        linear (bool, optional): Linear approximation.
    """
    tr, tt = twist_trans(tw, linear=linear)
    return np.dot(tr, rot), np.dot(t, tr.T) + tt

def twist_trans(tw, linear=False):
    """
    Convert from twist representation to transformation matrix.
    Args:
        tw (numpy.ndarray): Twist vector.
        linear (bool, optional): Linear approximation.
    """
    if linear:
        return np.identity(3) + skew(tw[:3]), tw[3:]
    else:
        twd = np.linalg.norm(tw[:3])
        if twd == 0.0:
            return np.identity(3), tw[3:]
        else:
            ntw = tw[:3] / twd
            c = np.cos(twd)
            s = np.sin(twd)
            tr = c * np.identity(3) + (1.0 - c) * np.outer(ntw, ntw) + s * skew(ntw)
            return tr, tw[3:]

EstepResult = namedtuple('EstepResult', ['momentZero','momentOne','momentTwo'])
MstepResult = namedtuple('MstepResult', ['transformation', 'q'])

class GMMTree():
    """GMM Tree
    Args:
        source (numpy.ndarray, optional): Source point cloud data.
        tree_level (int, optional): Maximum depth level of GMM tree.
        lambda_c (float, optional): Parameter that determine the pruning of GMM tree
    """
    def __init__(self, source=None, tree_level=5, lambda_c=0.01):
        self._source = source
        self._tree_level = tree_level
        self._lambda_c = lambda_c
        self._tf_type = RigidTransformation
        self._tf_result = self._tf_type()
        self._callbacks = []
        if not self._source is None:
            t1 = time.time()
            self._mixingCoeff,self._mean,self._covar = buildGMMTree(self._source,
                                                 self._tree_level,
                                                 20, 1.0e-4)
            t2 = time.time()

            print("Build tree Time: ",t2-t1)

            t1 = time.time()
            self._mixingCoeff,self._mean,self._covar = buildGMMTree(self._source,
                                        self._tree_level,
                                        20, 1.0e-4)
            t2 = time.time()

            print("Build tree Time: ",t2-t1)

            t1 = time.time()
            self._mixingCoeff,self._mean,self._covar = buildGMMTree(self._source,
                                        self._tree_level,
                                        20, 1.0e-4)
            t2 = time.time()

            print("Build tree Time: ",t2-t1)


    def set_source(self, source):
        self._source = source
        t1 = time.time()
        self._mixingCoeff,self._mean,self._covar = buildGMMTree(self._source,
                                                 self._tree_level,
                                                 20, 1.0e-4)

        t2 = time.time()
        print("Build tree Time: ",t2-t1)

    def set_callbacks(self, callbacks):
        self._callbacks = callbacks

    def expectation_step(self, target):
        #print("Node 1 value:",self._nodes[0].mixingCoeff)
        #print("Node 5 value:",self._nodes[5].mixingCoeff)
        #print("Node 10 value:",self._nodes[10].mixingCoeff)
        momentZero,momentOne,momentTwo = gmmTreeRegESTep(target, self._mixingCoeff,self._mean,self._covar, self._tree_level, self._lambda_c)
        return EstepResult(momentZero,momentOne,momentTwo)

    def maximization_step(self, estep_res, trans_p):
        momentsZero = estep_res.momentZero
        momentsOne = estep_res.momentOne
        momentsTwo = estep_res.momentTwo
        n = len(self._mixingCoeff)
        #print("length of moments are: ",n)
        #print("The length of moments are: ",n)
        #print("The moment is:",moments[0].zero,moments[0].one,moments[0].two)
        amat = np.zeros((n * 3, 6))
        bmat = np.zeros(n * 3)
        for i in range(len(momentsZero)):
            if momentsZero[i] < np.finfo(np.float32).eps:
                continue
            lmd, nn = np.linalg.eigh(self._covar[i])
            s = momentsOne[i] / momentsZero[i]
            nn = np.multiply(nn, np.sqrt(momentsZero[i] / lmd))
            sl = slice(3 * i, 3 * (i + 1))
            bmat[sl] = (np.dot(nn.T, self._mean[i].T) - np.dot(nn.T, s.T)).T
            amat[sl, :3] = np.cross(s, nn.T)
            amat[sl, 3:] = nn.T
        x, q, _, _ = np.linalg.lstsq(amat, bmat, rcond=-1)
        rot, t = twist_mul(x, trans_p.rot, trans_p.t)

        return MstepResult(RigidTransformation(rot, t), q)

    def registration(self, target, maxiter=20, tol=1.0e-4):
        q = None
        for _ in range(maxiter):
            t_target = self._tf_result.transform(target)
            estep_res = self.expectation_step(t_target)
            #print("Output of expectation Step:",estep_res)
            res = self.maximization_step(estep_res, self._tf_result)
            #print("Output of maximization Step:",res)
            self._tf_result = res.transformation
            for c in self._callbacks:
                c(self._tf_result.inverse())
            if not q is None and abs(res.q - q) < tol:
                break
            q = res.q
        return MstepResult(self._tf_result.inverse(), res.q)

def estimate_normals(pcd, params):
    if o3.__version__ >= '0.8.0.0':
        pcd.estimate_normals(search_param=params)
        pcd.orient_normals_to_align_with_direction()
    else:
        o3.estimate_normals(pcd, search_param=params)
        o3.orient_normals_to_align_with_direction(pcd)


def prepare_source_and_target_rigid_3d(source_filename,
                                       noise_amp=0.001,
                                       n_random=500,
                                       orientation=np.deg2rad([0.0, 0.0, 30.0]),
                                       translation=np.zeros(3),
                                       normals=False):
    source = o3.io.read_point_cloud(source_filename)
    source = o3.voxel_down_sample(source, voxel_size=0.005)
    print(source)
    target = copy.deepcopy(source)
    tp = np.asarray(target.points)
    np.random.shuffle(tp)
    rg = 1.5 * (tp.max(axis=0) - tp.min(axis=0))
    rands = (np.random.rand(n_random, 3) - 0.5) * rg + tp.mean(axis=0)
    target.points = o3.Vector3dVector(np.r_[tp + noise_amp * np.random.randn(*tp.shape), rands])
    ans = trans.euler_matrix(*orientation)
    ans[:3, 3] = translation
    target.transform(ans)
    if normals:
        estimate_normals(source, o3.geometry.KDTreeSearchParamHybrid(radius=0.3, max_nn=50))
        estimate_normals(target, o3.geometry.KDTreeSearchParamHybrid(radius=0.3, max_nn=50))
    return source, target

def registration_gmmtree(source, target, maxiter=20, tol=1.0e-4,
                         callbacks=[], **kargs):
    cv = lambda x: np.asarray(x.points if isinstance(x, o3.geometry.PointCloud) else x)
    gt = GMMTree(cv(source), **kargs)
    gt.set_callbacks(callbacks)
    return gt.registration(cv(target), maxiter, tol)

import copy
# load source and target point cloud

#voxel = 2.5

#voxel = 0.22
#voxel = 0.07
voxel = 0.032
#voxel = 0.0225
#voxel = 0.014

#source =  o3.io.read_point_cloud('lounge.ply')
source =  o3.io.read_point_cloud('bunny.pcd')
target = copy.deepcopy(source)
# transform target point cloud
th = np.deg2rad(30.0)

target.transform(np.array([[np.cos(th), -np.sin(th), 0.0, 0.0],
                           [np.sin(th), np.cos(th), 0.0, 0.0],
                           [0.0, 0.0, 1.0, 0.0],
                           [0.0, 0.0, 0.0, 1.0]]))
source = o3.voxel_down_sample(source, voxel_size=voxel)
target = o3.voxel_down_sample(target, voxel_size=voxel)
#sCheck = np.asarray(source.points)
#tCheck = np.asarray(target.points)
#print("Source points are:")
#print(sCheck[0:5])
#print("Target points are:")
#print(tCheck[0:5])
print(source)
# compute cpd registration
tf_param, _ = registration_gmmtree(source, target)
result = copy.deepcopy(source)
result.points = tf_param.transform(result.points)

# draw result
source.paint_uniform_color([1, 0, 0])
target.paint_uniform_color([0, 1, 0])
result.paint_uniform_color([0, 0, 1])
o3.draw_geometries([source, target, result])

#o3.draw_geometries([result])
